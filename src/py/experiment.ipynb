{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import web3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RQ 1 To what extend can pooled object hashes increase the transaction throughput and reduce cost for a fixity information storage service on the Ethereum blockchain?\n",
    "\n",
    "RQ 2 What is the optimal pool size based on the corruption rates of digital objects in the archive in terms of transaction throughput and cost?\n",
    "\n",
    "RQ 3 Given that metadata has a higher corruption rate, what effect has the split of metadata and objects on the operation cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12832/4142845066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"id: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" sha256: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" corruption_rate: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorruption_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mobjects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12832/4142845066.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"id: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" sha256: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" corruption_rate: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorruption_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mobjects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# creation of N = 10k objects and assigning them corruption rate from 1% to 20% \n",
    "encoding = \"utf-8\"\n",
    "N = 100\n",
    "percent = 10\n",
    "prevalence = (percent * N) /100.0\n",
    "p = percent/100.0\n",
    "\n",
    "class Object:\n",
    "    def __init__(self,id,corruption_rate,pool_id=0):\n",
    "        self.id=id\n",
    "        # sha256 string\n",
    "        self.pool_id=pool_id\n",
    "        # discuss if the pool_id should be hashed with the object in a real case\n",
    "        self.hash=hashlib.sha256(str(id).encode(encoding)).hexdigest()\n",
    "        # corruption rate from 0.01 to 0.2\n",
    "        self.corruption_rate=corruption_rate\n",
    "\n",
    "        self.is_corruped = False\n",
    "    def to_string(self):\n",
    "        return \"id: \" + str(self.id) + \" sha256: \" + self.hash + \" corruption_rate: \" + str(self.corruption_rate)\n",
    "        \n",
    "objects = [Object(i,random.uniform(0,p)) for i in range(0,N)]\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(objects[i].to_string())\n",
    "\n",
    "assert objects[2].hash == hashlib.sha256(\"2\".encode(encoding)).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal poolsize 4 with prevalence 10.0 in N=100\n",
      "Net analyses required for one object: 0.5939\n"
     ]
    }
   ],
   "source": [
    "# RQ 2\n",
    "# TODO finding the optimal pool size \"k\" with a bernoulli experiment based on the corruption rate\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8242460/\n",
    "import math\n",
    "def optimal_size(prevalence,N):\n",
    "    # https://www.sciencedirect.com/science/article/pii/S1201971220306925\n",
    "    # poolsize = 1.24* p/N ^-0.466\n",
    "    #return 100\n",
    "    return round(1.24 * math.pow(prevalence / N,-0.466)) \n",
    "k = optimal_size(prevalence,N)\n",
    "print(\"Optimal poolsize {} with prevalence {} in N={}\".format(k,prevalence,N))\n",
    "print(\"Net analyses required for one object: {}\".format(1/k-math.pow((1-p),k)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of J pools, fill them with objects and assign each object to a pool\n",
    "class Pool:\n",
    "    def __init__(self,objects,id=-1,transaction=\"\"):\n",
    "        # list of objects in the pool\n",
    "        self.objects=objects\n",
    "        # sha256 root hash of the hash-list\n",
    "        self.hash=hashlib.sha256(\"\".join([obj.hash for obj in objects]).encode(encoding)).hexdigest()\n",
    "        # reference to the pool, integer from 1 - inf \n",
    "        self.id=id\n",
    "        # transaction hash on the ethereum blockchain\n",
    "        self.transaction=transaction\n",
    "    def to_string(self):\n",
    "        return \"PoolId: \" + str(self.id) + \" with \" + str(len(self.objects)) +\" objects in pool\"\n",
    "\n",
    "test_n = 9\n",
    "testpool = Pool(objects[0:test_n])\n",
    "hashlist =\"\"\n",
    "for i in range(test_n):\n",
    "    hashlist+=hashlib.sha256(str(i).encode(encoding)).hexdigest()\n",
    "\n",
    "assert testpool.hash == hashlib.sha256(hashlist.encode(encoding)).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 objects distributed in 25 pools with size=4 last pool with size=4\n"
     ]
    }
   ],
   "source": [
    "# Pool Creation\n",
    "# https://www.geeksforgeeks.org/break-list-chunks-size-n-python/\n",
    "# split the list of pools into equal chunks of size k, the last pool is filled with remainders e.g. N= 14 k=3 = [3,3,3,3,2]\n",
    "#pools = [Pool(i,objects[i * k:(i + 1) * k]) for i in range((len(objects) + k - 1) // k )]\n",
    "\n",
    "pools=[]\n",
    "for i in range((len(objects) + k - 1) // k ):\n",
    "    # assign pool id to each object in the pool\n",
    "    for obj in objects[i * k:(i + 1) * k]:\n",
    "        obj.pool_id=i\n",
    "    pools.append(Pool(objects[i * k:(i + 1) * k],i))\n",
    "\n",
    "print(\"{} objects distributed in {} pools with size={} last pool with size={}\".format(N,len(pools),k,len(pools[len(pools)-1].objects)))\n",
    "assert pools[0].id == 0\n",
    "assert len(pools[0].objects) == len(pools[1].objects)\n",
    "assert pools[len(pools)-1].hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Count 191\n",
      "ETH Balance: 999.713875679871284508\n",
      "Sender Account: 0xAF8725604990d46042A50EfD9e2cB118141Bb140\n",
      "Contract Deployed at: 0x2C3c7752cE837bB97D6C31B4f883EAAA92BC3Ce5\n",
      "Contract Functions: [<Function getPoolHash(uint32)>, <Function setPoolHash(uint32,bytes32)>]\n"
     ]
    }
   ],
   "source": [
    "ganache_url = 'http://127.0.0.1:8545'\n",
    "contract_address=\"0x2C3c7752cE837bB97D6C31B4f883EAAA92BC3Ce5\"\n",
    "w3 = web3.Web3(web3.HTTPProvider(ganache_url))\n",
    "\n",
    "sender = w3.eth.accounts[0]\n",
    "balance = w3.fromWei(w3.eth.get_balance(sender),\"ether\")\n",
    "tx_count = w3.eth.getTransactionCount(sender)\n",
    "print(\"Transaction Count {}\".format(tx_count))\n",
    "print(\"ETH Balance: {}\".format(balance))\n",
    "print(\"Sender Account: {}\".format(sender))\n",
    "compiled_contract_path = '../sol/build/contracts/FixityStorage.json'\n",
    "# check contract address if this cell fails\n",
    "deployed_contract_address = w3.toChecksumAddress(contract_address)\n",
    "print(\"Contract Deployed at: {}\".format(deployed_contract_address))\n",
    "\n",
    "with open(compiled_contract_path) as file:\n",
    "    contract_json = json.load(file)  # load contract info as JSON\n",
    "    contract_abi = contract_json['abi']  # fetch contract's abi - necessary to call its functions\n",
    "\n",
    "# Fetch deployed contract reference\n",
    "contract = w3.eth.contract(address=deployed_contract_address, abi=contract_abi)\n",
    "print(\"Contract Functions: {}\".format(contract.all_functions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from': '0xAF8725604990d46042A50EfD9e2cB118141Bb140', 'to': '0x2C3c7752cE837bB97D6C31B4f883EAAA92BC3Ce5', 'gas': 2000000, 'gasPrice': 50000000000}\n",
      "191\n"
     ]
    }
   ],
   "source": [
    "# TODO get real world data \n",
    "gas = 2000000\n",
    "gasPrice = w3.toWei('50', 'gwei')\n",
    "\n",
    "metaTx = {\n",
    "    #\"nonce\":w3.eth.getTransactionCount(sender) nonce is set on transaction call\n",
    "    \"from\":sender,\n",
    "    \"to\":deployed_contract_address,\n",
    "    \"gas\": gas,\n",
    "    \"gasPrice\": gasPrice\n",
    "}\n",
    "print(metaTx)\n",
    "print(w3.eth.getTransactionCount(sender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15508cf1634f4c77940cfa35d352d5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# persist each pool on the blockchain, for each pool perform a transaction\n",
    "# RQ 1 write_tx_count * gasPrice * gas or just read it from ganache\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time\n",
    "write_tx_count = 0\n",
    "read_tx_count = 0\n",
    "\n",
    "for pool in tqdm(pools):\n",
    "    metaTx.update({\"nonce\":w3.eth.getTransactionCount(sender)})\n",
    "    tx_hash = contract.functions.setPoolHash(pool.id,pool.hash).transact(metaTx)\n",
    "    write_tx_count = write_tx_count + 1 \n",
    "    #print(\"Persisting pool \"+str(pool.id)+\" with hash: \"+str(pool.hash)+\" in transaction \" + tx_hash.hex() + \" succeeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44e7a7f7eae93fd3e0d52cfd81347de28c7f9312c6ec662617320e269a4243d9'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools[0].hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if persistence on the blockchain was successfull\n",
    "pool_id = pools[0].id\n",
    "poolHashBytes = contract.functions.getPoolHash(pool_id).call()\n",
    "read_tx_count = read_tx_count + 1\n",
    "assert poolHashBytes.hex() == pools[pool_id].hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ingest\" objects into the \"archive\"\n",
    "import random\n",
    "\n",
    "class Archive:\n",
    "    def __init__(self,objects):\n",
    "        self.objects=objects\n",
    "\n",
    "    def retrieveObj(self,id):\n",
    "        return next(obj for obj in objects if obj.id == id)\n",
    "\n",
    "    def get_objects_by_pool_id(self,pool_id):\n",
    "        return [obj for obj in self.objects if obj.pool_id == pool_id]\n",
    "    \n",
    "    def get_sample(self,n):\n",
    "        return random.sample(self.objects,n)\n",
    "\n",
    "    def corrupt(self,p):\n",
    "        for obj in self.objects:\n",
    "            if(random.uniform(0, 1)<p):\n",
    "                obj.hash=hashlib.sha256((str(obj.id) + \"x\").encode(encoding)).hexdigest()\n",
    "                obj.is_corruped=True\n",
    "\n",
    "    def repair(self,pool_id):\n",
    "        global write_tx_count\n",
    "        write_tx_count=write_tx_count+1\n",
    "        global metaTx\n",
    "        metaTx.update({\"nonce\":w3.eth.getTransactionCount(sender)})\n",
    "        contract.functions.setPoolHash(pool.id,pool.hash).transact(metaTx)\n",
    "        # TODO what happens if a corrupt pool was found\n",
    "        return 0\n",
    "    def clean(self):\n",
    "        print(\"Cleanup archive\")\n",
    "\n",
    "archive = Archive(objects)\n",
    "\n",
    "assert archive.objects[k*2].pool_id == 2 \n",
    "assert Pool(archive.get_objects_by_pool_id(2)).hash == pools[2].hash\n",
    "assert objects[2].hash==archive.retrieveObj(2).hash\n",
    "# write transactions have to be exactly the number of pools at this stage\n",
    "assert write_tx_count == len(pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write transactions after ingest: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Write transactions after ingest: \" + str(write_tx_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = archive.retrieveObj(0)\n",
    "assert sample.pool_id==0\n",
    "pool_of_sample = Pool(archive.get_objects_by_pool_id(sample.pool_id))\n",
    "assert pool_of_sample.hash == pools[0].hash\n",
    "pool_in_blockchain = contract.functions.getPoolHash(sample.pool_id).call()\n",
    "assert pool_of_sample.hash == pool_in_blockchain.hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update, zuerst schauen ob de rpool passt\n",
    "id = 0\n",
    "original_hash = archive.objects[id].hash\n",
    "archive.objects[id].hash=original_hash\n",
    "\n",
    "archive_pool = Pool(archive.get_objects_by_pool_id(archive.objects[id].pool_id),id=id)\n",
    "pool_in_blockchain = contract.functions.getPoolHash(archive.objects[id].pool_id).call()\n",
    "assert archive_pool.hash == pool_in_blockchain.hex()\n",
    "\n",
    "# falls ja das objekt ändern\n",
    "archive.objects[id].hash=original_hash+\"x\"\n",
    "# erneut die objekte aus dem pool im archiv holen und auf der blockchain persistieren\n",
    "updated_archive_pool = Pool(archive.get_objects_by_pool_id(archive.objects[id].pool_id),id=id)\n",
    "assert updated_archive_pool.hash!=pool_in_blockchain.hex()\n",
    "assert updated_archive_pool.id==id\n",
    "\n",
    "metaTx.update({\"nonce\":w3.eth.getTransactionCount(sender)})\n",
    "tx_hash = contract.functions.setPoolHash(updated_archive_pool.id,updated_archive_pool.hash).transact(metaTx)\n",
    "write_tx_count = write_tx_count + 1 \n",
    "\n",
    "# get the hash with pool id\n",
    "updated_pool_in_blockchain = contract.functions.getPoolHash(archive.objects[id].pool_id).call()\n",
    "assert pool_in_blockchain.hex() != updated_pool_in_blockchain.hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive.corrupt(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write transactions before cleaning: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455ff5025c45492189d4b7656cb55b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Distinct Cleaned Pools: 14\n",
      "Write transactions after cleaning: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Write transactions before cleaning: \" + str(write_tx_count))\n",
    "# repair every object in the archive\n",
    "already_cleaned_pool_ids = set()\n",
    "corrupted_objects_count = 0\n",
    "for obj in tqdm(archive.objects):\n",
    "    pool_of_sample = Pool(archive.get_objects_by_pool_id(obj.pool_id))\n",
    "    pool_in_blockchain = contract.functions.getPoolHash(obj.pool_id).call()\n",
    "\n",
    "    # is the local pool hash the same as the one in the blockchain? and make sure to not double repair a pool\n",
    "    if(pool_of_sample.hash != pool_in_blockchain.hex() and obj.pool_id not in already_cleaned_pool_ids):\n",
    "        write_tx_count=write_tx_count+1\n",
    "        metaTx.update({\"nonce\":w3.eth.getTransactionCount(sender)})\n",
    "        contract.functions.setPoolHash(pool.id,pool.hash).transact(metaTx)\n",
    "        already_cleaned_pool_ids.add(obj.pool_id)\n",
    "\n",
    "print(\"Number of Distinct Cleaned Pools: {}\".format(len(already_cleaned_pool_ids)))\n",
    "print(\"Write transactions after cleaning: {}\".format(write_tx_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal poolsize 4 with prevalence 10.0 in N=100\n",
      "100 objects distributed in 25 pools with size=4 last pool with size=4\n",
      "Transaction Count: 40 \n",
      "Total Cost=ETH 0.052997200000000000 for 40 transactions \n",
      "Theoretical amount of write transactions: 110.0 with N=100 + prevalence=10.0\n",
      "Repairing transactions=15, versus naive reparing transactions prevalence=10.0\n",
      "Number of Distinct Cleaned Pools: 14\n"
     ]
    }
   ],
   "source": [
    "fin_balance = w3.fromWei(w3.eth.get_balance(sender),\"ether\")\n",
    "fin_tx_count = w3.eth.getTransactionCount(sender)\n",
    "print(\"Optimal poolsize {} with prevalence {} in N={}\".format(k,prevalence,N))\n",
    "print(\"{} objects distributed in {} pools with size={} last pool with size={}\".format(N,len(pools),k,len(pools[len(pools)-1].objects)))\n",
    "print(\"Transaction Count: {} \".format(fin_tx_count - tx_count))\n",
    "print(\"Total Cost=ETH {} for {} transactions \".format((balance - fin_balance),(fin_tx_count - tx_count)))\n",
    "print(\"Theoretical amount of write transactions: {} with N={} + prevalence={}\".format((N+prevalence),N,prevalence))\n",
    "print(\"Repairing transactions={}, versus naive reparing transactions prevalence={}\".format(fin_tx_count-tx_count-len(pools),prevalence))\n",
    "print(\"Number of Distinct Cleaned Pools: {}\".format(len(already_cleaned_pool_ids)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO optimal pool size!!!!\n",
    "# TODO make a pretty result table \n",
    "# TODO experiment on online network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO nächstes mal auf ropsten testnet deployen und schauen was ich für einen throughput habe ud die kosten logge\n",
    "# simulieren soll ich den throughput und die kosten kann ich vorberechnen\n",
    "# rauber intressiert auch wie der thorughput vorberechnet ist und danach wie groß der unterschied zum tatsächliche throughput ist"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cbe5617e6ebb12e3da79bf67e991f578f8d59969394801378cf6f07e711918d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ds': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
